na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
View(graph_df3fil)
View(States)
View(States)
View(state_abbreviations)
state_code <- left_join(States, state_abbreviations, by = 'region')
graph_df3 <- left_join(state_code, freq_2000_vs_2020, by = 'code')
graph_df3[is.na(graph_df3)] = 0
graph_df3fil <- graph_df3 %>%
filter(pct_change >= 0)
ggplot(States) +
geom_polygon(data = graph_df3fil,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Disasters over Time",
subtitle = 'Percent Change in Disasters, 2000-2021',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
ggplot(States) +
geom_polygon(data = graph_df3fil,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Disasters over Time",
subtitle = 'Percent Change in Disasters, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
ggplot(States) +
geom_polygon(data = graph_df3fil,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters by Percent",
subtitle = '2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
ggplot(States) +
geom_polygon(data = graph_df3fil,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters",
subtitle = 'by %, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
library("readr")
library("dplyr")
library("ggplot2")
library("maps")
library("mapdata")
States <- map_data('state')
disaster_data <- read.csv("us_disaster_declarations.csv")
state_abbreviations <- read.csv("abbreviations.csv")
dis_by_st_2000 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2000)
frequency_2000 <- dis_by_st_2000 %>%
count('state')
colnames(frequency_2000) <- c('code', 'class', 'freq')
colnames(state_abbreviations) <- c('state', 'abbr.', 'code')
frequency_code_2000 <- left_join(frequency_2000, state_abbreviations, by = 'code')
colnames(frequency_code_2000) <- c('code', 'class', 'freq_2000', 'region', 'abbrev')
dis_by_st_2020 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2020)
frequency_2020 <- dis_by_st_2020 %>%
count('state')
colnames(frequency_2020) <- c('code', 'class', 'freq')
frequency_code_2020 <- left_join(frequency_2020, state_abbreviations, by = 'code')
colnames(frequency_code_2020) <- c('code', 'class', 'freq_2020', 'region', 'abbrev')
freq_2000_vs_2020 <- left_join(frequency_2020, frequency_2000, by = 'code')
colnames(freq_2000_vs_2020) <- c('code', 'class_2020', 'freq_2020', 'class_2000', 'freq_2000')
freq_2000_vs_2020 <- freq_2000_vs_2020 %>%
mutate(net_change = (freq_2020 - freq_2000)) %>%
mutate(pct_change = (net_change / freq_2020)*100)
colnames(state_abbreviations) <- c('region', 'abbrev', 'code')
state_abbreviations$region = tolower(state_abbreviations$region)
state_code <- left_join(States, state_abbreviations, by = 'region')
graph_df3 <- left_join(state_code, freq_2000_vs_2020, by = 'code')
graph_df3[is.na(graph_df3)] = 0
graph_df3fil <- graph_df3 %>%
filter(pct_change >= 0)
ggplot(States) +
geom_polygon(data = graph_df3fil,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters",
subtitle = 'by %, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
# Load datasets
natural_disasters <- read.csv("https://raw.githubusercontent.com/info-201a-sp22/exploratory-analysis-raymondsmith939/main/us_disaster_declarations.csv?token=GHSAT0AAAAAABTAT5A5YK4QODH6TJ7KS5ZIYT62Y6Q")
disasters_each_year <- natural_disasters %>% group_by(fy_declared) %>% summarise(number_disasters = n())
year_max_disasters <- disasters_each_year %>% filter(number_disasters == max(number_disasters)) %>% pull(fy_declared)
ggplot(disasters_each_year) +
geom_line(mapping = aes(x = fy_declared, y = number_disasters), color = "blue") +
geom_point(mapping = aes(x = fy_declared, y = number_disasters), color  = "red") +
labs(title = "Number of disasters by year", x = "Year", y = "Number of diasters") +
scale_x_continuous(breaks = round(seq(1953, 2022, by = 1))) +
scale_y_continuous(breaks = round(seq(0, 9500, by = 1000))) +
theme(axis.text.x = element_text(angle = 90))
us_disaster_declarations <- read_csv("https://raw.githubusercontent.com/info-201a-sp22/exploratory-analysis-raymondsmith939/main/us_disaster_declarations.csv?token=GHSAT0AAAAAABTAT5A5YK4QODH6TJ7KS5ZIYT62Y6Q")
WA_disaster <- us_disaster_declarations %>%
filter(state == 'WA')
ggplot (WA_disaster, aes(incident_begin_date)) +
geom_histogram() +
labs(title = "Number of Disasters in Washington by year", x = "Year", y = "Number of diasters")
disasters_each_year <- WA_disaster %>% group_by(fy_declared) %>% summarise(number_disasters = n())
pct_change <- max(disasters_each_year$number_disasters) / min(disasters_each_year$number_disasters)
pct_change
States <- map_data('state')
disaster_data <- read.csv("us_disaster_declarations.csv")
state_abbreviations <- read.csv("abbreviations.csv")
## 2000 DATA
# Filter Disasters in 2000
dis_by_st_2000 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2000)
# Frequency of Disasters in 2000
frequency_2000 <- dis_by_st_2000 %>%
count('state')
# Renaming to Left_Join Later
colnames(frequency_2000) <- c('code', 'class', 'freq')
colnames(state_abbreviations) <- c('state', 'abbr.', 'code')
# Combining Frequency with Abbreviations
frequency_code_2000 <- left_join(frequency_2000, state_abbreviations, by = 'code')
# Renaming for future Left_Join
colnames(frequency_code_2000) <- c('code', 'class', 'freq_2000', 'region', 'abbrev')
## 2020 DATA
# Filter for 2020 Disasters
dis_by_st_2020 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2020)
# Frequency of Disasters in 2020
frequency_2020 <- dis_by_st_2020 %>%
count('state')
# Renaming Columns for Join
colnames(frequency_2020) <- c('code', 'class', 'freq')
# Combining Frequency and State Names for future join
frequency_code_2020 <- left_join(frequency_2020, state_abbreviations, by = 'code')
# Renaming columns for future join
colnames(frequency_code_2020) <- c('code', 'class', 'freq_2020', 'region', 'abbrev')
## Combining and Comparing
# Combine the 2000 and 2020 data into a single dataframe
freq_2000_vs_2020 <- left_join(frequency_2020, frequency_2000, by = 'code')
# Rename columns to join into graph dataset
colnames(freq_2000_vs_2020) <- c('code', 'class_2020', 'freq_2020', 'class_2000', 'freq_2000')
# Create new variables: Change in Disasters, % Change in Disasters
freq_2000_vs_2020 <- freq_2000_vs_2020 %>%
mutate(net_change = (freq_2020 - freq_2000)) %>%
mutate(pct_change = (net_change / freq_2020)*100)
# Renaming columns to left_join later
colnames(state_abbreviations) <- c('region', 'abbrev', 'code')
state_abbreviations$region = tolower(state_abbreviations$region)
# Combining the state names with their 2-digit code
state_code <- left_join(States, state_abbreviations, by = 'region')
# The data for the graph! States template + frequency data
graph_df3 <- left_join(state_code, freq_2000_vs_2020, by = 'code')
# Filtering out NA, negative values to focus on INCREASE
graph_df3[is.na(graph_df3)] = 0
graph_df3fil <- graph_df3 %>%
filter(pct_change >= 0)
# The Map!
ggplot(States) +
geom_polygon(data = graph_df3fil,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters",
subtitle = 'by %, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
library("readr")
library("dplyr")
library("ggplot2")
library("maps")
library("mapdata")
States <- map_data('state')
disaster_data <- read.csv("us_disaster_declarations.csv")
state_abbreviations <- read.csv("abbreviations.csv")
## 2000 DATA
# Filter Disasters in 2000
dis_by_st_2000 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2000)
# Frequency of Disasters in 2000
frequency_2000 <- dis_by_st_2000 %>%
count('state')
# Renaming to Left_Join Later
colnames(frequency_2000) <- c('code', 'class', 'freq')
colnames(state_abbreviations) <- c('state', 'abbr.', 'code')
# Combining Frequency with Abbreviations
frequency_code_2000 <- left_join(frequency_2000, state_abbreviations, by = 'code')
# Renaming for future Left_Join
colnames(frequency_code_2000) <- c('code', 'class', 'freq_2000', 'region', 'abbrev')
## 2020 DATA
# Filter for 2020 Disasters
dis_by_st_2020 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2020)
# Frequency of Disasters in 2020
frequency_2020 <- dis_by_st_2020 %>%
count('state')
# Renaming Columns for Join
colnames(frequency_2020) <- c('code', 'class', 'freq')
# Combining Frequency and State Names for future join
frequency_code_2020 <- left_join(frequency_2020, state_abbreviations, by = 'code')
# Renaming columns for future join
colnames(frequency_code_2020) <- c('code', 'class', 'freq_2020', 'region', 'abbrev')
## Combining and Comparing
# Combine the 2000 and 2020 data into a single dataframe
freq_2000_vs_2020 <- left_join(frequency_2020, frequency_2000, by = 'code')
# Rename columns to join into graph dataset
colnames(freq_2000_vs_2020) <- c('code', 'class_2020', 'freq_2020', 'class_2000', 'freq_2000')
# Create new variables: Change in Disasters, % Change in Disasters
freq_2000_vs_2020 <- freq_2000_vs_2020 %>%
mutate(net_change = (freq_2020 - freq_2000)) %>%
mutate(pct_change = (net_change / freq_2020)*100)
# Renaming columns to left_join later
colnames(state_abbreviations) <- c('region', 'abbrev', 'code')
state_abbreviations$region = tolower(state_abbreviations$region)
# Combining the state names with their 2-digit code
state_code <- left_join(States, state_abbreviations, by = 'region')
# The data for the graph! States template + frequency data
graph_df3 <- left_join(state_code, freq_2000_vs_2020, by = 'code')
# Filtering out NA, negative values to focus on INCREASE
graph_df3[is.na(graph_df3)] = 0
graph_df3fil <- graph_df3 %>%
filter(pct_change >= 0)
# The Map!
ggplot(States) +
geom_polygon(data = graph_df3fil,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters",
subtitle = 'by %, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
graph_df3_increase <- graph_df3 %>%
filter(pct_change >= 0)
ggplot(States) +
geom_polygon(data = graph_df3_increase,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters",
subtitle = 'by %, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
us_disaster_declarations <- read.csv("https://raw.githubusercontent.com/info-201a-sp22/exploratory-analysis-raymondsmith939/main/us_disaster_declarations.csv?token=GHSAT0AAAAAABTAT5A5JXG5ZL2R432RMLO2YT62FMA")
summary_info <- list()
summary_info <- append(summary_info, pct_change)
summary_info <- append(summary_info, year_max_disasters)
setwd("~/Desktop/INFO_201/Final Project/exploratory-analysis-raymondsmith939")
summary_info <- list()
summary_info <- append(summary_info, pct_change)
summary_info <- append(summary_info, year_max_disasters)
library("readr")
library("dplyr")
library("ggplot2")
library("maps")
library("mapdata")
States <- map_data('state')
disaster_data <- read.csv("us_disaster_declarations.csv")
state_abbreviations <- read.csv("abbreviations.csv")
## 2000 DATA
# Filter Disasters in 2000
dis_by_st_2000 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2000)
# Frequency of Disasters in 2000
frequency_2000 <- dis_by_st_2000 %>%
count('state')
# Renaming to Left_Join Later
colnames(frequency_2000) <- c('code', 'class', 'freq')
colnames(state_abbreviations) <- c('state', 'abbr.', 'code')
# Combining Frequency with Abbreviations
frequency_code_2000 <- left_join(frequency_2000, state_abbreviations, by = 'code')
# Renaming for future Left_Join
colnames(frequency_code_2000) <- c('code', 'class', 'freq_2000', 'region', 'abbrev')
## 2020 DATA
# Filter for 2020 Disasters
dis_by_st_2020 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2020)
# Frequency of Disasters in 2020
frequency_2020 <- dis_by_st_2020 %>%
count('state')
# Renaming Columns for Join
colnames(frequency_2020) <- c('code', 'class', 'freq')
# Combining Frequency and State Names for future join
frequency_code_2020 <- left_join(frequency_2020, state_abbreviations, by = 'code')
# Renaming columns for future join
colnames(frequency_code_2020) <- c('code', 'class', 'freq_2020', 'region', 'abbrev')
## Combining and Comparing
# Combine the 2000 and 2020 data into a single dataframe
freq_2000_vs_2020 <- left_join(frequency_2020, frequency_2000, by = 'code')
# Rename columns to join into graph dataset
colnames(freq_2000_vs_2020) <- c('code', 'class_2020', 'freq_2020', 'class_2000', 'freq_2000')
# Create new variables: Change in Disasters, % Change in Disasters
freq_2000_vs_2020 <- freq_2000_vs_2020 %>%
mutate(net_change = (freq_2020 - freq_2000)) %>%
mutate(pct_change = (net_change / freq_2020)*100)
# Renaming columns to left_join later
colnames(state_abbreviations) <- c('region', 'abbrev', 'code')
state_abbreviations$region = tolower(state_abbreviations$region)
# Combining the state names with their 2-digit code
state_code <- left_join(States, state_abbreviations, by = 'region')
# The data for the graph! States template + frequency data
graph_df3 <- left_join(state_code, freq_2000_vs_2020, by = 'code')
# Filtering out NA, negative values to focus on INCREASE
graph_df3[is.na(graph_df3)] = 0
graph_df3_increase <- graph_df3 %>%
filter(pct_change >= 0)
# The Map!
ggplot(States) +
geom_polygon(data = graph_df3_increase,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters",
subtitle = 'by %, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
graph_df3_increase <- graph_df3 %>%
filter(pct_change >= 0)
graph_df3 <- left_join(state_code, freq_2000_vs_2020, by = 'code')
state_code <- left_join(States, state_abbreviations, by = 'region')
state_abbreviations <- read.csv("abbreviations.csv")
state_abbreviations <- read.csv("abbreviations.csv")
library("readr")
library("dplyr")
library("ggplot2")
library("maps")
library("mapdata")
States <- map_data('state')
disaster_data <- read.csv("us_disaster_declarations.csv")
state_abbreviations <- read.csv("abbreviations.csv")
## 2000 DATA
# Filter Disasters in 2000
dis_by_st_2000 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2000)
# Frequency of Disasters in 2000
frequency_2000 <- dis_by_st_2000 %>%
count('state')
# Renaming to Left_Join Later
colnames(frequency_2000) <- c('code', 'class', 'freq')
colnames(state_abbreviations) <- c('state', 'abbr.', 'code')
# Combining Frequency with Abbreviations
frequency_code_2000 <- left_join(frequency_2000, state_abbreviations, by = 'code')
# Renaming for future Left_Join
colnames(frequency_code_2000) <- c('code', 'class', 'freq_2000', 'region', 'abbrev')
## 2020 DATA
# Filter for 2020 Disasters
dis_by_st_2020 <- disaster_data %>%
group_by(state) %>%
filter(fy_declared == 2020)
# Frequency of Disasters in 2020
frequency_2020 <- dis_by_st_2020 %>%
count('state')
# Renaming Columns for Join
colnames(frequency_2020) <- c('code', 'class', 'freq')
# Combining Frequency and State Names for future join
frequency_code_2020 <- left_join(frequency_2020, state_abbreviations, by = 'code')
# Renaming columns for future join
colnames(frequency_code_2020) <- c('code', 'class', 'freq_2020', 'region', 'abbrev')
## Combining and Comparing
# Combine the 2000 and 2020 data into a single dataframe
freq_2000_vs_2020 <- left_join(frequency_2020, frequency_2000, by = 'code')
# Rename columns to join into graph dataset
colnames(freq_2000_vs_2020) <- c('code', 'class_2020', 'freq_2020', 'class_2000', 'freq_2000')
# Create new variables: Change in Disasters, % Change in Disasters
freq_2000_vs_2020 <- freq_2000_vs_2020 %>%
mutate(net_change = (freq_2020 - freq_2000)) %>%
mutate(pct_change = (net_change / freq_2020)*100)
# Renaming columns to left_join later
colnames(state_abbreviations) <- c('region', 'abbrev', 'code')
state_abbreviations$region = tolower(state_abbreviations$region)
# Combining the state names with their 2-digit code
state_code <- left_join(States, state_abbreviations, by = 'region')
# The data for the graph! States template + frequency data
graph_df3 <- left_join(state_code, freq_2000_vs_2020, by = 'code')
# Filtering out NA, negative values to focus on INCREASE
graph_df3[is.na(graph_df3)] = 0
graph_df3_increase <- graph_df3 %>%
filter(pct_change >= 0)
# The Map!
ggplot(States) +
geom_polygon(data = graph_df3_increase,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters",
subtitle = 'by %, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
ggplot(States) +
geom_polygon(data = graph_df3_increase,
aes(x = long, y = lat, group=group, fill = pct_change),
color = "white") +
labs(title = "Increase in Natural Disasters",
subtitle = 'by %, 2000-2020',
x = "Longitude",
y = "Latitude") +
scale_fill_fermenter(
type = "seq",
palette = "Oranges",
direction = 1,
na.value = "grey50",
guide = "colourbar",
aesthetics = "fill"
)
largest_pct_increase <- graph_df3_increase %>%
summarize(largest_pct_increase = max(pct_change))
View(largest_pct_increase)
View(graph_df3_increase)
largest_pct_increase <- graph_df3_increase %>%
summarize(largest_pct_increase = max(pct_change)) %>%
pull(region)
largest_pct_increase <- graph_df3_increase %>%
filter(pct_change == max(pct_change)) %>%
pull(region)
largest_pct_increase <- graph_df3_increase %>%
filter(pct_change == max(pct_change)) %>%
pull(unique(region))
largest_pct_increase <- graph_df3_increase %>%
filter(pct_change == max(pct_change)) %>%
pull(unique(region))
# Which U.S. state experienced the greatest increase in natural disasters since 2000?
largest_pct_increase <- graph_df3_increase %>%
filter(pct_change == max(pct_change)) %>%
pull(region)
summary_info <- append(summary_info, largest_pct_state_increase)
summary_info <- list()
summary_info <- append(summary_info, pct_change)
